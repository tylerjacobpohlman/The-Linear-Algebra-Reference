---
layout: default
---

# Subspace

## \#Definition Subspace

A **subspace** of $\mathbb{R}^{n}$ is a subset $S\subseteq\mathbb{R}^{n}$ such that:

1. $\vec{0}\in S$
1. If $\vec{u},\vec{v}\in S$, then $\vec{u}+\vec{v}\in S$ **Closure under addition**
1. If $\vec{u}\in S$ and $c\in\mathbb{R}$, then $c\vec{u}\in S$ **Closure under scalar multiplication**

### \#Remark Subspace

Combining properties (2) and (3) results in **closure under linear combinations**.

* If $\vec{v\_{1}},\vec{v\_{2}},\dots,\vec{v\_{n}}\in S$ and $c\_{1},c\_{2},\dots,c\_{n}\in\mathbb{R}$ then:
  $$c\_{1}\vec{v\_{1}}+c\_{2}\vec{v\_{2}}+\dots+c\_{k}\vec{v\_{k}}\in S$$

### \#Example Subspace of Itself

$W=\mathbb{R}^{n}$ is a subspace of itself.

### \#Example Zero Vector and Subspaces

$W={\vec{0}}$ is a subspace of $\mathbb{R}^{n}$.

### \#Example Determining Whether a Set is a Subspace

Consider whether or not $W={\begin{bmatrix}a\\b\end{bmatrix}\in\mathbb{R}^{2} :  a,b \geq 0}$ is a subspace of $\mathbb{R}^{2}$.
$W$ is not a subspace due to [property (3](3.5%20Subspaces,%20Basis,%20Dimension,%20and%20Rank.html#definition-subspace)%20of%20subspaces), **closure under scalar multiplication**:
If $\vec{u}=\begin{bmatrix}1\\2\end{bmatrix}$ and $c=-1$, then $\vec{u}=\begin{bmatrix}1\\2\end{bmatrix}\in W$ but $c\vec{u}=(-1)\begin{bmatrix}1\\2\end{bmatrix}=\begin{bmatrix}-1\\-2\end{bmatrix}\notin W$.

### \#Example Showing a Set is a Subspace

Show that $W={\begin{bmatrix}x\\y\\z\end{bmatrix}\in\mathbb{R}^{3} : x+2y=3z}$ is a subspace of $\mathbb{R}^{3}$.
Following the [definition of a subspace](3.5%20Subspaces,%20Basis,%20Dimension,%20and%20Rank.html#definition-subspace), show the following:

1. $\vec{0}\in S$

1. If $\vec{u},\vec{v}\in S$, then $\vec{u}+\vec{v}\in S$ 

1. If $\vec{u}\in S$ and $c\in\mathbb{R}$, then $c\vec{u}\in S$

1. 

$\vec{0}=\begin{bmatrix}0\\0\\0\end{bmatrix}$ satisfies the equation $x+2y=3z$.

2. 

Suppose $\vec{u}=\begin{bmatrix}u\_{1}\\u\_{2}\\u\_{3}\end{bmatrix},\vec{v}=\begin{bmatrix}v\_{1}\\v\_{2}\\v\_{3}\end{bmatrix}\in W$.  Following the equation $x+2y=3z$:
$$u\_{1}+2u\_{2}=3u\_{3}$$
$$v\_{1}+2v\_{2}=3v\_{3}$$
Now, prove $\vec{u}+\vec{v}=\begin{bmatrix}u\_{1}+v\_{1} \\ u\_{2}+v\_{2} \\ u\_{3}+v\_{3}\end{bmatrix}\in W$. Following the equation $x+2y=3z$:
$$(u\_{1}+v\_{1})+2(u\_{2}+v\_{2})=3(u\_{3}+v\_{3})$$
$$u\_{1}+2u\_{2}+v\_{1}+2v\_{2}=3u\_{3}+v\_{3}$$
Using the equations $u\_{1}+2u\_{2}=3u\_{3}$ and $v\_{1}+2v\_{2}=3v\_{3}$:
$$3u\_{3}+3v\_{3}=3u\_{3}+3v\_{3}$$
Given that the equations are equal, then $\vec{u}+\vec{v}\in W$.

3. 

Suppose $\vec{v}=\begin{bmatrix}v\_{1}\\v\_{2}\\v\_{3}\end{bmatrix}\in W$ and $c\in\mathbb{R}$. Following the equation $x+2y=3z$:
$$v\_{1}+2v\_{2}=3v\_{3}$$
Now, prove $c\vec{u}=\begin{bmatrix}cv\_{1} \\ cv\_{2} \\ cv\_{3}\end{bmatrix}\in W$. Following the equation $x+2y=3z$:
$$cv\_{1}+2cv\_{2}=3cv\_{3}$$
Using the equation $v\_{1}+2v\_{2}=3v\_{3}$:
$$c(v\_{1}+2v\_{2})=3cv\_{3}$$
$$c(3v\_{3})=3cv\_{3}$$
$$3cv\_{3}=3cv\_{3}$$
Given that the equations are equal, then $c\vec{v}\in W$.

## \#Theorem Span and Subspace

Let $\vec{v\_{1}},\vec{v\_{2}},\dots,\vec{v\_{k}}$ be vectors in $\mathbb{R}^{n}$. Then $span(\vec{v\_{1}},\vec{v\_{2}},\dots,\vec{v\_{k}})$ is a subspace of $\mathbb{R}^{n}$. 

# Subspaces Associated with Matrices

## \#Definition Row Space and Column Space

Let $A$ be an *m x n* matrix. the **row space**, denoted $Row(A)$, is the [subspace](3.5%20Subspaces,%20Basis,%20Dimension,%20and%20Rank.html#definition-subspace) of $\mathbb{R}^{n}$ spanned by the rows of $A$. The **column space**, denoted $Col(A)$, is the [subspace](3.5%20Subspaces,%20Basis,%20Dimension,%20and%20Rank.html#definition-subspace) of $\mathbb{R}^{n}$ spanned by the columns of $A$.

### \#Example Row Space and Column Space

Let $A=\begin{bmatrix}1&-1 \\ 0&1 \\ 3&-3\end{bmatrix}$.  1) Is  $\vec{b}=\begin{bmatrix}1 \\ 2 \\ 3\end{bmatrix}\in Col(A)$? 2) Is $\vec{w}=\begin{bmatrix}4&5\end{bmatrix}\in Row(A)$? 3) Describe $Row(A)$ and $Col(A)$.

1. 

$\vec{b}\in Col(A)$ if $\vec{b}$ is a linear combination of the of the columns of $A$, which is true if and only if the linear system $A\vec{x}=\vec{b}$ is consistent. As such, determine whether or not there's any pivots in the constant column of the augmented matrix $\begin{bmatrix}A & | & \vec{b} \end{bmatrix}$. This is found by row reducing the augmented matrix to a row echelon form.
$$\left\[ 
\\begin{array}{cc|c}
1 & -1 & 1 \\
0 & 1 & 2 \\
3 & -3 & 3
\\end{array}
\\right\]→^{Guass‎‎ \ \ Elimination}\dots \left\[\] 
\\begin{array}{cc|c}
① & -1 & 1 \\
0 & ① & 2 \\
0 & 0 & 0
\\end{array}
\\right\]$$
Given that there's no pivots in the constants column, then $\vec{b}\in Col(A)$.
2) 
Elementary row operations replace a row of a matrix with a linear combination of rows. As such, if $\vec{w}\in Row(A)$, then $\vec{w}$ is a linear combination of the rows of $A$. Given this information, it follows that the augmented matrix $\left\[\\begin{array}{c}A \\\hline\vec{w}\end{array}\right\]$ can be reduced to $\left\[\\begin{array}{c}A' \\\hline\vec{0}\end{array}\right\]$ using only elementary row operations. In other words, $\vec{w}\in Row(A)$ if the augmented matrix, after row reduce, has a zero row.
$$\left\[\\begin{array}{c}1&-1 \\ 0&1 \\ 3 & -3 \\ \hline 4&5 \end{array}\right\]→^{Guass‎‎ \ \ Elimination}\dots \left\[\\begin{array}{c}1&-1 \\ 0&1 \\ 0&9 \\ \hline 0&0 \end{array}\right\]$$
Given that there's a zero row, then $\vec{w}\in Row(A)$.
3) 
In order to describe $Col(A)$, determine under what conditions a generic matrix $\vec{x}=\begin{bmatrix}x\_{1}\\x\_{2}\\x\_{3}\end{bmatrix}\in Col(A)$. Following part (1):
$$
\\left\[ \begin{array}{cc|c}
1 & -1 & x\_{1} \\
0 & 1 & x\_{2} \\
3 & -3 & x\_{3}
\\end{array}\right\]
R\_{3}-3R\_{1}→R\_{3}
\\left\[ \begin{array}{cc|c}
1 & -1 & x\_{1} \\
0 & 1 & x\_{2} \\
0 & 0 & x\_{3}-3x\_{1}
\\end{array}\right\]
$$
Given that $\vec{x}=\begin{bmatrix}x\_{1}\\x\_{2}\\x\_{3}\end{bmatrix}\in Col(A)$ if there are no pivots in the constant columns, then it follows that:
$$x\_{3}-3x\_{1}=0$$
$$x\_{3}=3x\_{1}$$
As such 
$$Col(A)={\begin{bmatrix} x\_{1} \\ x\_{2} \\ x\_{3} \end{bmatrix}\in\mathbb{R}^{3} : x\_{1},x\_{2},x\_{3}\in\mathbb{R}, x\_{3}=3x\_{1}}$$
$$Col(A)={\begin{bmatrix}x\_{1}\\x\_{2}\\3x\_{1}\end{bmatrix} : x,y\in\mathbb{R}}$$
$$Col(A)={x\_{1}\begin{bmatrix}1\\0\\3\end{bmatrix} + x\_{2}\begin{bmatrix}0\\1\\0\end{bmatrix}: x,y\in\mathbb{R}}$$
$$Col(A)=Span{\begin{bmatrix}1\\0\\3\end{bmatrix}, \begin{bmatrix}0\\1\\0\end{bmatrix}}$$
In order to describe $Row(A)$, determine under what conditions a generic matrix $\vec{y}=\begin{bmatrix}y\_{1}&y\_{2}&y\_{3}\end{bmatrix}\in Row(A)$. Following part (2):
$$
\\left\[\\begin{array}{c}1&-1 \\ 0&1 \\ 3 & -3 \\ \hline y\_{1}&y\_{2} \end{array}\right\]
R\_{4}-y\_{1}R\_{1}→R\_{4}
\\left\[\\begin{array}{c}1&-1 \\ 0&1 \\ 3&-3 \\ \hline 0&y\_{1}+y\_{2} \end{array}\right\]
R\_{3}-3R\_{1}→R\_{3}
\\left\[\\begin{array}{c}1&-1 \\ 0&1 \\ 0&0 \\ \hline 0&y\_{1}+y\_{2} \end{array}\right\]
R\_{3}↔R\_{4}
\\left\[\\begin{array}{c}1&-1 \\ 0&1 \\ 0&y\_{1}+y\_{2} \\ \hline 0&0 \end{array}\right\]
R\_{3}-3R\_{1}→R\_{3}
$$
Given that there's a zero row regardless of the values of either $y\_{1}$ and/or $y\_{2}$, then it follows that $\vec{y}=\begin{bmatrix}y\_{1}&y\_{2}&y\_{3}\end{bmatrix}\in Row(A)$ **for all** $\vec{y}=\begin{bmatrix}y\_{1}&y\_{2}&y\_{3}\end{bmatrix}\in \mathbb{R}$. As such:
$$Row(A)=\mathbb{R}^{2}$$

### \#Remark Row Space and Column Space

* $Row(A^{T})=Col(A^{T})$
* $Col(A^{T})=Row(A)$

## \#Theorem Row Equivalence

Two *m x n* matrices $A$ and $B$ are **row equivalent** if either can be obtained from the other by applying a sequence of elementary row operations.

* If $A$ and $B$ are **row equivalent**, then $Row(A)=Row(B)$.
* In particular, if $R$ is a row echelon form of $A$, then $Row(A)=Row(R)$.

## \#Definition Null Space

Let $A$ be an *m x n* matrix. The **null space** of $A$, denoted $Null(A)$, is the subspace of $\mathbb{R}^{n}$ consisting of solutions to the homogeneous linear system $A\vec{x}=\vec{0}$.
$$\text{Null}(A) = \left{ \vec{x} \in \mathbb{R}^{n} \mid A\vec{x} = \vec{0} \right}$$

### \#Remark Null Space

If $A$ and $R$ are row equivalent, then $Null(A)=Null(R)$.

## \#Theorem Solutions to $A\vec{x}=\vec{b}$

Let $A$ be a *m x n* matrix and $\vec{b}\in\mathbb{R}^{m}$. The linear system $A\vec{x}=\vec{b}$ either has (1) no solution, (2) a unique solution, or (3) infinitely many solutions. 

# Basis

## \#Definition Basis

Let $S$ be a subspace of $\mathbb{R}^{n}$. A **basis** $B$ for $S$ is a subset of $S$ such that:

1. $B$ spans $S$
1. $B$ is linearly independent

### \#Example Showing a Set is a Basis

Show that $B= {\begin{bmatrix}2\\-1\end{bmatrix}, \begin{bmatrix}1\\3\end{bmatrix}}$ is a basis for $\mathbb{R}^{2}$.
Following the [definition of a basis](3.5%20Subspaces,%20Basis,%20Dimension,%20and%20Rank.html#definition-basis), first setup a matrix $A$ whose columns are that of $B$.
$$A=\begin{bmatrix}2&1\\-1&3\end{bmatrix}$$
Then, reduce $A$ to a row echelon form.
$$\begin{bmatrix}2&1\\-1&3\end{bmatrix} →^{Guass‎‎ \ \ Elimination} = \begin{bmatrix}①&-3\\0&⑦\end{bmatrix}=R$$
Since $R$ has a pivot in every column, $B$ is linearly independent. Likewise, since $R$ has a pivot in every row, $B$ spans $\mathbb{R}^{2}$.

### \#Example Bases and Standard Unit Vectors

The standard unit vectors in $\mathbb{R}^{n}$ - $\vec{e\_{1}}=\begin{bmatrix} 1 \\ 0 \\ 0 \\ \vdots \\ 0 \end{bmatrix}, \vec{e\_{2}}=\begin{bmatrix} 0 \\ 1 \\ 0 \\ \vdots \\ 0 \end{bmatrix},\dots \vec{e\_{n}}=\begin{bmatrix} 0 \\ 0 \\ \vdots \\ 0 \\ 1 \end{bmatrix}$ - form a basis for $\mathbb{R}^{n}$.

### \#Example Find a Row Space's Basis

Let $A=\begin{bmatrix} 1&1&3&1&6 \\ 2&-1&0&1&-1 \\ -3&2&1&-2&1 \\ 4&1&6&1&3 \end{bmatrix}$. Find a basis for $Row(A)$.
Recall the [theorem for row equivalence](3.5%20Subspaces,%20Basis,%20Dimension,%20and%20Rank.html#theorem-row-equivalence), *if $R$ is a row echelon form of $A$, then $Row(A)=Row(R)$.* As such, use Gauss-Jordan Elimination to find the reduced row echelon form of $A$.
$$\begin{bmatrix} 1&1&3&1&6 \\ 2&-1&0&1&-1 \\ -3&2&1&-2&1 \\ 4&1&6&1&3 \end{bmatrix} →^{Guass‎‎-Jordan \ \ Elimination}
\\begin{bmatrix} ①&0&1&0&-1 \\ 0&①&2&0&3 \\ 0&0&0&①&4 \\ 0&0&0&0&0 \end{bmatrix} = R$$
Given $Row(A)=Row(R)$, then $Row(A)$ is spanned by the top three rows of $R$. Likewise, these row vectors are linearly independent. As such, the basis for $Row(A)$ is
$${\begin{bmatrix}1&0&1&0&-1\end{bmatrix}, \begin{bmatrix}0&1&2&0&3\end{bmatrix}, \begin{bmatrix}0&0&0&1&4\end{bmatrix}}$$

### \#Example Find a Column Space's Basis

Let $A=\begin{bmatrix} 1&1&3&1&6 \\ 2&-1&0&1&-1 \\ -3&2&1&-2&1 \\ 4&1&6&1&3 \end{bmatrix}$. Find a basis for $Col(A)$.
$Col(A)$ is found using the $Null(A)$. If $A=\left\[ \begin{array}{c|c|c} \vec{a\_{1}} & \vec{a\_{2}} & \dots & \vec{a\_{n}} \end{array}\right\]$ and $\vec{x}=\begin{bmatrix} x\_{1} \\ x\_{2} \\ \vdots \\ x\_{n} \end{bmatrix}$, then:
$$\vec{x}\in Null(A)$$
$$A\vec{x}=\vec{0}$$
$$x\_{1}\vec{a\_{1}}+x\_{2}\vec{a\_{2}}+\dots+x\_{n}\vec{a\_{n}}=\vec{0}$$
As such, the elements of the $Null(A)$ corresponds to linear relations among the columns of $A$. In other words, through row reduction, the row echelon form of $A$ determines which columns have a pivot in them. Using the pivots, the basis of $Col(A)$ are the columns in the original matrix $A$ which have a pivot in their row echelon form.

If $A$ and $R$ are row equivalent, then $Null(A)=Null(R)$. As such, use Gauss-Jordan Elimination to find the reduced row echelon form of $A$.
$$\begin{bmatrix} 1&1&3&1&6 \\ 2&-1&0&1&-1 \\ -3&2&1&-2&1 \\ 4&1&6&1&3 \end{bmatrix} →^{Guass‎‎-Jordan \ \ Elimination}
\\begin{bmatrix} ①&0&1&0&-1 \\ 0&①&2&0&3 \\ 0&0&0&①&4 \\ 0&0&0&0&0 \end{bmatrix} = R$$
As such, the basis for $Col(A)$ is
$${ \begin{bmatrix}1\\2\\-3\\4\end{bmatrix}, \begin{bmatrix}1\\-1\\2\\1\end{bmatrix}, \begin{bmatrix}1\\1\\-2\\1\end{bmatrix} }$$

#### \#Remark $Col(A)\neq Col(R)$

### \#Example Find a Null Space's Basis

Let $A=\begin{bmatrix} 1&1&3&1&6 \\ 2&-1&0&1&-1 \\ -3&2&1&-2&1 \\ 4&1&6&1&3 \end{bmatrix}$. Find a basis for $Null(A)$.
Given that $Null(A)=Null(R)$, then find a row echelon of $A$.
$$\begin{bmatrix} 1&1&3&1&6 \\ 2&-1&0&1&-1 \\ -3&2&1&-2&1 \\ 4&1&6&1&3 \end{bmatrix} →^{Guass‎‎-Jordan \ \ Elimination}
\\begin{bmatrix} ①&0&1&0&-1 \\ 0&①&2&0&3 \\ 0&0&0&①&4 \\ 0&0&0&0&0 \end{bmatrix} = R$$
Then setup and solve the augmented matrix $\left\[ \begin{array}{c|c}R&\vec{0}\end{array}\right\]$.
$$\left\[ \begin{array}{ccccc|c} ①&0&1&0&-1&0 \\ 0&①&2&0&3&0 \\ 0&0&0&①&4&0 \\ 0&0&0&0&0&0 \end{array}\right\]$$
If $\vec{x}=\begin{bmatrix}x\_{1}\\x\_{2}\\x\_{3}\\x\_{4}\\x\_{5}\end{bmatrix}$, then solve for $x\_{1}$, $x\_{2}$, and $x\_{4}$ in terms of the free variables of $x\_{3}$ and $x\_{5}$. Using the augmented matrix:
$$x\_{1}=-x\_{3}+x\_{5}$$
$$x\_{2}=-2x\_{3}-3x\_{5}$$
$$x\_{4}=-4x\_{5}$$
Meaning $\vec{x} = \begin{bmatrix}-x\_{3}+x\_{5}\\-2x\_{3}-3x\_{5}\\x\_{3}\\x\_{4}\\x\_{5}\end{bmatrix} = x\_{3}\begin{bmatrix}-1\\-2\\1\\0\\0\end{bmatrix} + x\_{5}\begin{bmatrix}1\\-3\\0\\-4\\1\end{bmatrix}$.  As such, the basis for the $null(A)$ is
$$\left{ \begin{bmatrix}-1\\-2\\1\\0\\0\end{bmatrix},\begin{bmatrix}1\\-3\\0\\-4\\1\end{bmatrix} \right}$$

### \#Remark Basis

If $W\subseteq\mathbb{R}^{n}$ is a subspace and $S\subseteq W$ spans $W$, then $S$ contains a basis for $W$.

## \#Procedure Finding the Row Space, Column Space, and Null Space of a Matrix

Let $A$ represent an *n x n* matrix.

1. Find the reduced row echelon form $R$ of $A$.
1. Use the nonzero row vectors to form a basis for $row(A)$.
1. Use the column vectors of $A$ that correspond to the columns of $R$ containing pivots to form a basis for $col(A)$.
1. Solve the linear equation $R\vec{x}=\vec{0}$ in terms of the free variables, set the basic variables equal to the free variables, substitute those basic variables into $\vec{x}$, and write the result as a linear combination of vectors. These vectors form a basis for $null(A)$.

# Dimension and Rank

## \#Theorem The Basis Theorem

Let $S$ be a [subspace](3.5%20Subspaces,%20Basis,%20Dimension,%20and%20Rank.html#definition-subspace) of $\mathbb{R}^{n}$. Any two bases for $S$ have the same number of vectors.

## \#Definition Dimension

If $S$ is a [subspace](3.5%20Subspaces,%20Basis,%20Dimension,%20and%20Rank.html#definition-subspace) of $\mathbb{R}^{n}$, then the number of vectors in a [basis](3.5%20Subspaces,%20Basis,%20Dimension,%20and%20Rank.html#definition-basis) for $S$ is called the **dimension** of $S$, denoted $dim(S)$.

### \#Example $dim(\vec{0})=0$ because $\vec{0}$ has no basis.

## \#Definition Rank

The **rank** of a matrix $A$, denoted $rank(A)$, is the dimension of its [row space and column space](3.5%20Subspaces,%20Basis,%20Dimension,%20and%20Rank.html#definition-row-space-and-column-space).

### \#Example 1

Since the standard basis for $\mathbb{R}^{n}$, ${\vec{e\_{1}},\vec{e\_{2}},\dots,\vec{e\_{n}}}$, has $n$ vectors, then $dim(\mathbb{R}^{n})=n$. 

### \#Example 2

Suppose $R$ is a row echelon form of a given matrix. Then, $dim(Row(R))=$ *\# number of rows in R* $=$ *\# of pivots of R* $=$ $rank(R)$.

## \#Theorem Rank and Transpose Equivalency

For any matrix $A$,
$$rank(A^{T})=rank(A)$$

## \#Definition Nullity

The **nullity** of a matrix $A$, denoted $nullity(A)$, is the [dimension](3.5%20Subspaces,%20Basis,%20Dimension,%20and%20Rank.html#definition-dimension) of its [null space](3.5%20Subspaces,%20Basis,%20Dimension,%20and%20Rank.html#definition-null-space).

## \#Theorem Rank-Nullity Theorem

If $A$ is an *m x n* matrix then,
$$rank(A)+nullity(A)=n$$

## \#Theorem The Fundamental Theorem of Invertible Matrices: Version 2

This theorem builds off of [The Fundamental Theorem of Invertible Matrices: Version 1](3.3%20The%20Inverse%20of%20a%20Matrix.html#theorem-the-fundamental-theorem-of-invertible-matrices-version-1), adding 8 more equivalency statements.

Let $A$ be an *n x n* matrix. The following statements are equivalent :

1. $A$ is invertible.
1. $A\vec{x}=\vec{b}$ has a unique solution for every $\vec{b}$ in $\mathbb{R}^{n}$.
1. $A\vec{x}=\vec{0}$ has only the trivial solution. In other words, the only solution is $\vec{x}=\vec{0}$.
1. The reduced row echelon form of $A$ is $I\_{n}$.
1. $A$ is a product of elementary matrices.
1. $rank(A)=n$.
1. $nullity(A)=0$.
1. The columns of $A$ are linearly independent.
1. The column vectors of $A$ span $\mathbb{R}^{n}$.
1. The column vectors of A form a basis for $\mathbb{R}^{n}$.
1. The row vectors of $A$ are linearly independent.
1. The row vectors of $A$ span $\mathbb{R}^{n}$.
1. The row vectors of $A$ form a basis for $\mathbb{R}^{n}$.

## \#Theorem Rank and Transpose

Let $A$ be an *m x n* matrix. Then:

1. $rank(A^{T}A)=rank(A)$
1. The *n x n* matrix $A^{T}A$ is invertible if and only if $rank(A)=n$.
